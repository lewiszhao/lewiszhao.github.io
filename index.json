[{"authors":["admin"],"categories":null,"content":"I received the M.S degree from Institute of Image Processing and Pattern Recognition at Shanghai Jiao Tong University, led by Prof. Jie Yang. After graduation, I worked in the Tencent, engaged in R\u0026amp;D for Tencent cloud. Now I am a lecture at the Chongqing University of Education, focusing on the research of computer vision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://lewiszhao.github.io/author/lewis-zhao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/lewis-zhao/","section":"authors","summary":"I received the M.S degree from Institute of Image Processing and Pattern Recognition at Shanghai Jiao Tong University, led by Prof. Jie Yang. After graduation, I worked in the Tencent, engaged in R\u0026amp;D for Tencent cloud.","tags":null,"title":"Lewis Zhao","type":"authors"},{"authors":["Yu Zhao","Keren Fu","Qiaoyuan Shu","Pengcheng Wei","Xi Shi"],"categories":[],"content":"","date":1583904659,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583904659,"objectID":"80cd3f4236132415f7e2a61449cf00ac","permalink":"https://lewiszhao.github.io/publication/mdrf/","publishdate":"2020-05-10T13:30:59+08:00","relpermalink":"/publication/mdrf/","section":"publication","summary":"Person re-identification (re-ID) aims at matching two pedestrian images across different cameras. Usually, the main scheme of re-ID based on deep learning includes two phases: feature extraction and metric calculation. We focus on how to extract more discriminative image features for re-ID. To address this problem, we propose a multilevel deep representation fusion (MDRF) model based on the convolutional neural network. Specifically, the MDRF model is designed to extract image features at different network levels through one forward pass. In order to produce the final image representation, these multilevel features are fused by a fusion layer. Then the final image representation is fed into a combined loss of the softmax and the triplet to optimize the model. The proposed method not only utilizes the abstract information of high-level features but also integrates the appearance information of low-level features. Extensive experiments on public datasets including Market-1501, DukeMTMC-reID, and CUHK03 demonstrate the effectiveness of the proposed method for person re-ID.","tags":[],"title":"Multilevel deep representation fusion for person re-identification","type":"publication"},{"authors":["Pengcheng Wei","Yu Zhao"],"categories":[],"content":"","date":1561355207,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561355207,"objectID":"e5ef231827c7ba2475f7c00f226bed23","permalink":"https://lewiszhao.github.io/publication/sdae/","publishdate":"2020-05-10T13:46:47+08:00","relpermalink":"/publication/sdae/","section":"publication","summary":"Since the contextual information has an important impact on the speakerâ€™s emotional state, how to use emotion-related context information to conduct feature learning is a key problem. The existing speech emotion recognition algorithms achieve the relatively high recognition rate; these algorithms are not very good application to the real-life speech emotion recognition systems. Therefore, in order to address the abovementioned issues, a novel speech emotion recognition algorithm based on improved stacked kernel sparse deep model is proposed in this paper, which is based on auto-encoder, denoising auto-encoder, and sparse auto-encoder to improve the Chinese speech emotion recognition. The first layer of the structure uses a denoising auto-encoder to learn a hidden feature with a larger dimension than the dimension of the input features, and the second layer employs a sparse auto-encoder to learn sparse features. Finally, a wavelet-kernel sparse SVM classifier is applied to classify the features. The proposed algorithm is evaluated on the testing dataset, which contains the speech emotion data of spontaneous, non-prototypical, and long-term. The experimental results show that the proposed algorithm outperforms the existing state-of-the-art algorithms in speech emotion recognition.","tags":[],"title":"A novel speech emotion recognition algorithm based on wavelet kernel sparse classifier in stacked deep auto-encoder model","type":"publication"},{"authors":["Lei Zhou","Yu Zhao","Jie Yang","Qi Yu","Xun Xu"],"categories":[],"content":"","date":1521697554,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521697554,"objectID":"ce237d9edcd9487cc0a0823e7645bbe2","permalink":"https://lewiszhao.github.io/publication/dmil/","publishdate":"2020-05-10T13:45:54+08:00","relpermalink":"/publication/dmil/","section":"publication","summary":"As a weakly supervised learning technique, multiple instance learning (MIL) has shown an advantage over supervised learning methods for automatic detection of diabetic retinopathy (DR): only the image-level annotation is needed to achieve both detection of DR images and DR lesions, making more graded and de-identified retinal images available for learning. However, the performance of existing studies on this technique is limited by the use of handcrafted features. The authors propose a deep MIL method for DR detection, which jointly learns features and classifiers from data and achieves a significant improvement on detecting DR images and their inside lesions. Specifically, a pre-trained convolutional neural network is adapted to achieve the patch-level DR estimation, and then global aggregation is used to make the classification of DR images. Further, the authors propose an end-to-end multi-scale scheme to better deal with the irregular DR lesions. For detection of DR images, they achieve an area under the ROC curve of 0.925 on a subset of a Kaggle dataset, and 0.960 on Messidor. For detection of DR lesions, they achieve an F1-score of 0.924 with sensitivity 0.995 and precision 0.863 on DIARETDB1 using the connected component-level validation.","tags":[],"title":"Deep multiple instance learning for automatic detection of diabetic retinopathy in retinal images","type":"publication"},{"authors":["Yu Zhao","Lei Zhou","Keren Fu","Jie Yang"],"categories":[],"content":"","date":1473486307,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473486307,"objectID":"530974f308512d5ed3a439737757ec32","permalink":"https://lewiszhao.github.io/publication/aadnllc/","publishdate":"2020-05-10T13:45:07+08:00","relpermalink":"/publication/aadnllc/","section":"publication","summary":"In this paper, an approach using the spatio-temporal feature and nonnegative locality-constrained linear coding (NLLC) is proposed to detect abnormal events in videos. This approach utilizes position-based spatio-temporal descriptors as the low-level representations of a video clip. Each descriptor consists of the position information of a space-time interest point and an appearance feature vector. To obtain the high-level video representations, the nonnegative locality-constrained linear coding is adopted to encode each spatio-temporal descriptor. Then, the max pooling integrates all NLLC codes of a video clip to produce a feature vector. Finally, the support vector machine (SVM) is employed to classify the feature vector as abnormal or normal. Experimental results on two datasets have demonstrated the promising performance of the proposed approach in the detection of both global and local abnormal events.","tags":[],"title":"Abnormal event detection using spatio-temporal feature and nonnegative locality-constrained linear coding","type":"publication"},{"authors":["Yu Zhao","Yu Qiao","Jie Yang","Nikola Kirilov Kasabov"],"categories":[],"content":"","date":1447134299,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1447134299,"objectID":"688e70703293ec5f30bfd0377d7845bf","permalink":"https://lewiszhao.github.io/publication/aadlsr/","publishdate":"2020-05-10T13:44:59+08:00","relpermalink":"/publication/aadlsr/","section":"publication","summary":"Abnormal activity detection in a video is a challenging and attractive task. In this paper, an approach using spatio-temporal feature and Laplacian sparse representation is proposed to tackle this problem. To detect the abnormal activity, we first detect interest points of a query video in the spatio-temporal domain. Then normalized combinational vectors, named HNF, are computed around the detected space-time interest points to characterize the video. After that, we utilize the Laplacian sparse representation framework and maximum pooling method to gain a more discriminative feature vector from the HNF set. Finally, the support vector machine (SVM) is adopted to classify the feature vector as normal or abnormal. Experiments on two datasets demonstrate the satisfactory performance of the proposed approach.","tags":[],"title":"Abnormal Activity Detection Using Spatio-Temporal Feature and Laplacian Sparse Representation","type":"publication"}]